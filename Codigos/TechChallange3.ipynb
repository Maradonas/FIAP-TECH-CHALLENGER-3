{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d6ca84",
   "metadata": {},
   "source": [
    "#### **Fundamentos de Bancos de Dados Relacionais e NoSQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59115f",
   "metadata": {},
   "source": [
    "#### **Conteúdo - Bases e Notebook da aula**\n",
    "\n",
    "https://github.com/FIAP/Pos_Tech_DTAT/tree/main/Fase%203"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770d68e",
   "metadata": {},
   "source": [
    "#### **Importação de pacotes, bibliotecas e funções (def)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ccd403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: botocore 1.40.26\n",
      "Uninstalling botocore-1.40.26:\n",
      "  Successfully uninstalled botocore-1.40.26\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall boto3 -y\n",
    "!pip uninstall botocore -y\n",
    "# !pip install boto3==1.40.26 \n",
    "# !pip install botocore==1.40.26\n",
    "# # !pip install s3fs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bccaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting botocore==1.40.26\n",
      "  Using cached botocore-1.40.26-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\dmaradini\\appdata\\local\\anaconda3\\lib\\site-packages (from botocore==1.40.26) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\dmaradini\\appdata\\local\\anaconda3\\lib\\site-packages (from botocore==1.40.26) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\dmaradini\\appdata\\local\\anaconda3\\lib\\site-packages (from botocore==1.40.26) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dmaradini\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.40.26) (1.16.0)\n",
      "Using cached botocore-1.40.26-py3-none-any.whl (14.0 MB)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.69\n",
      "    Uninstalling botocore-1.34.69:\n",
      "      Successfully uninstalled botocore-1.34.69\n",
      "Successfully installed botocore-1.40.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.40.26 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#!pip install boto3==1.40.26 \n",
    "!pip install botocore==1.40.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691abc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3: 1.40.26\n",
      "botocore: 1.40.26\n"
     ]
    }
   ],
   "source": [
    "import boto3, botocore\n",
    "print(\"boto3:\", boto3.__version__)\n",
    "print(\"botocore:\", botocore.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5ca788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar biblioteca completa\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "import requests\n",
    "import botocore\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import mongomock\n",
    "import fakeredis\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "# Importar função especifica de um módulo\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from dotenv import load_dotenv\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from astrapy import DataAPIClient\n",
    "# from cassandra.cluster import Cluster\n",
    "# from cassandra.auth import PlainTextAuthProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f092b",
   "metadata": {},
   "source": [
    "#### **Testar conexão AWS via Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02baef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conectado à conta\n",
      "\n",
      "UserId: AROAZI2LFHB2TERRDYNA4:user4377774=maradinidiego16@gmail.com\n",
      "Account: 637423401077\n",
      "Arn: arn:aws:sts::637423401077:assumed-role/voclabs/user4377774=maradinidiego16@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# Validar conexão\n",
    "try:\n",
    "    session = boto3.Session(profile_name=\"default\")\n",
    "    sts = session.client(\"sts\")\n",
    "    identity = sts.get_caller_identity()\n",
    "    print(\"✅ Conectado à conta\\n\")\n",
    "    print(\"UserId:\", identity[\"UserId\"])\n",
    "    print(\"Account:\", identity[\"Account\"])\n",
    "    print(\"Arn:\", identity[\"Arn\"])\n",
    "\n",
    "except (BotoCoreError, ClientError) as e:\n",
    "    print(\"❌ Erro ao conectar à AWS. Verifique suas credenciais e tente novamente.\")\n",
    "    print(\"Detalhes do erro:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d94c24",
   "metadata": {},
   "source": [
    "##### **Conectar ao PostgreSQL via RDS + Executar Comandos SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c30e3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement StringIO (from versions: none)\n",
      "ERROR: No matching distribution found for StringIO\n"
     ]
    }
   ],
   "source": [
    "%pip install StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc352e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\dmaradini\\AppData\\Local\\Temp\\ipykernel_22456\\2708774549.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  load_dotenv(\"Users\\dmaradini\\.aws\\credentials\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv(\"Users\\dmaradini\\.aws\\credentials\")\n",
    "\n",
    "aws_access_key_id       = os.getenv(\"aws_access_key_id\")\n",
    "aws_secret_access_key   = os.getenv(\"aws_secret_access_key\")\n",
    "aws_session_token       = os.getenv(\"aws_session_token\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00071434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão estabelecida.\n",
      "Bucket 'techchallange-637423401077' já existe e está acessível.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as npfrp\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id       =   aws_access_key_id\n",
    "    ,aws_secret_access_key  =   aws_secret_access_key\n",
    "    ,aws_session_token      =   aws_session_token\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "bucket_name = \"techchallange-637423401077\"\n",
    "s3_prefix = \"raw\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Conexão estabelecida.\")\n",
    "\n",
    "s3 = session.client('s3')\n",
    "region = s3.meta.region_name or \"us-east-1\"\n",
    "\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' já existe e está acessível.\")\n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code in (\"404\", \"NoSuchBucket\"):\n",
    "        print(f\"Bucket '{bucket_name}' não existe, criando...\\n\")\n",
    "        if region == \"us-east-1\":\n",
    "            s3.create_bucket(Bucket=bucket_name)\n",
    "            \n",
    "        else:\n",
    "            s3.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={'LocationConstraint': region}\n",
    "            )\n",
    "        print(f\"Bucket '{bucket_name}' criado com sucesso.\\n\")\n",
    "    else:\n",
    "        print(f\"Erro ao acessar o bucket: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b14473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando PNAD_COVID_052020...\n",
      "Dados salvos no S3 em s3://techchallange-637423401077/raw/PNAD_COVID_052020.csv\n",
      "Processando PNAD_COVID_062020...\n",
      "Dados salvos no S3 em s3://techchallange-637423401077/raw/PNAD_COVID_062020.csv\n",
      "Processando PNAD_COVID_072020...\n",
      "Dados salvos no S3 em s3://techchallange-637423401077/raw/PNAD_COVID_072020.csv\n",
      "Processando Dicionario_PNAD_COVID_052020...\n",
      "Dicionário salvo no S3 em s3://techchallange-637423401077/raw/Dicionario_PNAD_COVID_052020.xls\n",
      "Processando Dicionario_PNAD_COVID_062020...\n",
      "Dicionário salvo no S3 em s3://techchallange-637423401077/raw/Dicionario_PNAD_COVID_062020.xls\n",
      "Processando Dicionario_PNAD_COVID_072020...\n",
      "Dicionário salvo no S3 em s3://techchallange-637423401077/raw/Dicionario_PNAD_COVID_072020.xls\n",
      "Exportação concluída com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import BytesIO, StringIO\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "\n",
    "bucket_name = \"techchallange-637423401077\"\n",
    "s3_prefix = \"raw\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# URLs dos arquivos do IBGE\n",
    "urls = {\n",
    "    \"PNAD_COVID_052020\": \"https://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_PNAD_COVID19/Microdados/Dados/PNAD_COVID_052020.zip\",\n",
    "    \"PNAD_COVID_062020\": \"https://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_PNAD_COVID19/Microdados/Dados/PNAD_COVID_062020.zip\",\n",
    "    \"PNAD_COVID_072020\": \"https://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_PNAD_COVID19/Microdados/Dados/PNAD_COVID_072020.zip\",\n",
    "}\n",
    "\n",
    "for tabela, url in urls.items():\n",
    "    print(f\"Processando {tabela}...\")\n",
    "\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if \"Dicionario\" in tabela:\n",
    "        # Salvar o XLS original no S3\n",
    "        s3_key = f\"{s3_prefix}/{tabela}.xls\"\n",
    "        s3.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=s3_key,\n",
    "            Body=r.content  # conteúdo binário do XLS\n",
    "        )\n",
    "        print(f\"Dicionário salvo no S3 em s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "    else:\n",
    "        # Abrir o ZIP e extrair o CSV\n",
    "        with ZipFile(BytesIO(r.content)) as z:\n",
    "            csv_name = z.namelist()[0]\n",
    "            with z.open(csv_name) as f:\n",
    "                df = pd.read_csv(f, sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "        # Converter para CSV em memória\n",
    "        csv_buffer = StringIO()\n",
    "        df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "        s3_key = f\"{s3_prefix}/{tabela}.csv\"\n",
    "        s3.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=s3_key,\n",
    "            Body=csv_buffer.getvalue()\n",
    "        )\n",
    "        print(f\"Dados salvos no S3 em s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "print(\"Exportação concluída com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90a04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consegui conectar no S3!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.Session(profile_name=\"default\")\n",
    "s3 = session.client(\"s3\")\n",
    "print(\"Consegui conectar no S3!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdffda6",
   "metadata": {},
   "source": [
    "##CAMADA SILVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b2f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo https://techchallange-637423401077.s3.us-east-1.amazonaws.com/raw/PNAD_COVID_052020.csv\n",
      "Lendo https://techchallange-637423401077.s3.us-east-1.amazonaws.com/raw/PNAD_COVID_062020.csv\n",
      "Lendo https://techchallange-637423401077.s3.us-east-1.amazonaws.com/raw/PNAD_COVID_072020.csv\n",
      "(1114742, 145)\n",
      "0   Ano  UF CAPITAL RM_RIDE V1008 V1012 V1013 V1016  Estrato        UPA  ...  \\\n",
      "0  2020  11      11            01     4    05     1  1110011  110015970  ...   \n",
      "1  2020  11      11            01     4    05     1  1110011  110015970  ...   \n",
      "2  2020  11      11            01     4    05     1  1110011  110015970  ...   \n",
      "3  2020  11      11            01     4    05     1  1110011  110015970  ...   \n",
      "4  2020  11      11            03     2    05     1  1110011  110015970  ...   \n",
      "\n",
      "0 E001 E0021 E0022 E0023 E0024 F002A1 F002A2 F002A3 F002A4 F002A5  \n",
      "0  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "1  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "2  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "3  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "4  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "\n",
      "[5 rows x 145 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Lista de arquivos CSV no bucket público\n",
    "bronze_files = [\n",
    "    \"PNAD_COVID_052020.csv\",\n",
    "    \"PNAD_COVID_062020.csv\",\n",
    "    \"PNAD_COVID_072020.csv\"\n",
    "]\n",
    "\n",
    "# URL base do bucket público\n",
    "base_url = \"https://techchallange-637423401077.s3.us-east-1.amazonaws.com/raw/\"\n",
    "\n",
    "lista_de_dataframes = []\n",
    "\n",
    "for file_name in bronze_files:\n",
    "    file_url = f\"{base_url}{file_name}\"\n",
    "    print(f\"Lendo {file_url}\")\n",
    "    \n",
    "    # Faz download do CSV como texto\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()  # garante que deu certo\n",
    "    \n",
    "    # Lê o CSV como texto cru\n",
    "    df_raw = pd.read_csv(StringIO(response.text), header=None)\n",
    "    \n",
    "    # Divide a única coluna pelo separador vírgula\n",
    "    df_temp = df_raw[0].str.split(\",\", expand=True)\n",
    "    \n",
    "    # Define a primeira linha como header\n",
    "    df_temp.columns = df_temp.iloc[0]\n",
    "    df_temp = df_temp.drop(0).reset_index(drop=True)\n",
    "    \n",
    "    lista_de_dataframes.append(df_temp)\n",
    "\n",
    "# Consolidar todos os dataframes\n",
    "df_consolidado = pd.concat(lista_de_dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039dae51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>UF</th>\n",
       "      <th>CAPITAL</th>\n",
       "      <th>RM_RIDE</th>\n",
       "      <th>V1008</th>\n",
       "      <th>V1012</th>\n",
       "      <th>V1013</th>\n",
       "      <th>V1016</th>\n",
       "      <th>Estrato</th>\n",
       "      <th>UPA</th>\n",
       "      <th>...</th>\n",
       "      <th>E001</th>\n",
       "      <th>E0021</th>\n",
       "      <th>E0022</th>\n",
       "      <th>E0023</th>\n",
       "      <th>E0024</th>\n",
       "      <th>F002A1</th>\n",
       "      <th>F002A2</th>\n",
       "      <th>F002A3</th>\n",
       "      <th>F002A4</th>\n",
       "      <th>F002A5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0   Ano  UF CAPITAL RM_RIDE V1008 V1012 V1013 V1016  Estrato        UPA  ...  \\\n",
       "0  2020  11      11            01     4    05     1  1110011  110015970  ...   \n",
       "1  2020  11      11            01     4    05     1  1110011  110015970  ...   \n",
       "2  2020  11      11            01     4    05     1  1110011  110015970  ...   \n",
       "3  2020  11      11            01     4    05     1  1110011  110015970  ...   \n",
       "4  2020  11      11            03     2    05     1  1110011  110015970  ...   \n",
       "\n",
       "0 E001 E0021 E0022 E0023 E0024 F002A1 F002A2 F002A3 F002A4 F002A5  \n",
       "0  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "1  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4  NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Seu DataFrame\n",
    "# df_consolidado\n",
    "\n",
    "# Configurações do bucket\n",
    "bucket_name = \"techchallange-637423401077\"\n",
    "s3_key = \"silver/df_consolidado.parquet\"\n",
    "\n",
    "# Conexão S3\n",
    "s3_client = boto3.client(\"s3\")  # precisa das credenciais configuradas no seu ambiente\n",
    "\n",
    "# Salva o DataFrame em um buffer Parquet\n",
    "buffer = BytesIO()\n",
    "df_consolidado.to_parquet(buffer, index=False)\n",
    "\n",
    "# Envia para o S3\n",
    "buffer.seek(0)\n",
    "s3_client.put_object(Bucket=bucket_name, Key=s3_key, Body=buffer.getvalue())\n",
    "\n",
    "print(f\"DataFrame salvo em s3://{bucket_name}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a068bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
